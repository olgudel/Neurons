################################################################################
#
#                                Libraries
#
################################################################################
import numpy as np
import matplotlib.pyplot as plt

################################################################################
#
#                                 Classes
#
################################################################################

class Neuron:
    """
    Neuron class that takes a dictionary of arguments with keys:
    
    name (str) - The name of the neuron
    n_type (str: ex, inh_v, inh_pr, inh_f, inh_tv, inh_kv) -
                The type of neuron it is: excitatory, voltage inhibitatory,
                vesicle release inhibitatory, etc... 
    M (int) - number of docked vesicles
    E (int) - number of empty vesicles
    k (float)
    pr (float)
    f (float: between 0 and 1)
    vth (float)
    tv (float)
    kv (float)
    v (float)
    other (dictionary: key/values "pr":(percentage), "f":(percentage), "tv":(float), "kv":(float))
    
    
    """
    def __init__(self, neuron_args, n_tests):

        #Create all class attributes from the neuron_args dictionary.
        self.__dict__.update((k, v) for k, v in neuron_args.items())

##  The names of the attributes will be:
##
##        self.name, self.n_type, self.M, self.E, self.k,
##        self.pr, self.f, self.v0, 
##        self.vth, self.tv, self.kv, 
##        self.v, self.AP_length, self.A, self.tau, self.other


##        #History arguments
##        self.v_hist = []
##        self.b_hist = self.f

        
        #Incase the neuron is inhibited, keep a copy of the original values
        self.pr_original = self.pr
        self.f_original = self.f
        self.tv_original = self.tv
        self.kv_original = self.kv

        #Triggers that prevent an inhibition from producing an increasing effect
        self.pr_changed = False
        self.f_changed = False
        self.tv_changed = False
        self.kv_changed = False

        #Initialize empty connection dictionary
        self.pre_connections = {}
        self.post_connections = {}



#

        self.n_tests = n_tests

        self.preneuron_voltage_contributions = {}

        self.contribution_queues = {}
        
        self.queue_size = self.AP_length
        self.voltage_queue = Queue(self.queue_size)
        
        self.net_voltage_history = np.zeros(n_tests)
        #Net voltage history
        #Voltage history for each presynaptic neuron contribution
        #Every instance, update the net and the contributions by
        #adding the front value from the queue.  Then shift the queue.

        
        #If AP, then voltage_queue.set_values(AP) but add the value it's currently
        #at to the first one and then set_values.

#


        
    def pre(self):
        #Return pre_neuron connections
        return self.pre_connections
    
    def post(self):
        #Return post_neuron connections
        return self.post_connections

    def add_pre(self, N):
        #Add a neuron to the pre_connection_list
        self.pre_connections[N.name] = N
        self.preneuron_voltage_contributions[N.name] = Queue(self.AP_length)

    
    def add_post(self, N):
        #Add a neuron to the post_connection list
        self.post_connections[N.name] = N

    def AP(self):
        #Generate an presynaptic action potential
        #into the postsynaptic neurons with their associated effects
        
        def update_voltage_contributions(pc):
            
            def AP_function():
                return self.A * np.exp(-np.arange(self.AP_length)/self.tau)
                
##            self.M
##            self.E
##            self.k
##            self.pr
##            self.f
##            self.tv
            pc.v += 1

            pc.preneuron_voltage_contributions[self.name].update_values(AP_function())
           
##        def update_net_voltage():
##            self.net_voltage_sum = np.zeros(self.AP_length)
##            for name, contribution in self.preneuron_voltage_contributions:
##                self.net_voltage_sum += contribution 
##            
##            self.net_voltage_history[self.timer:self.timer+self.AP_length] = \
##                [self.preneuron_voltage_contributions[name]]
##            

        if self.n_type == 'ex':
            for name in self.post_connections.keys():
                update_voltage_contributions(self.post_connections[name])

        #Directly changes the voltage of the neuron    
        if self.n_type == 'inh_v':
            for name in self.post_connections.keys():
                update_voltage_contributions(self.post_connections[name])


        if self.n_type == 'inh_pr':
            for name in self.post_connections.keys():
                if self.post_connections[name].pr_changed == False:
                    self.post_connections[name].pr *= self.other['pr']
                    self.post_connections[name].pr_changed = True
                update_voltage_contributions(self.post_connections[name])
            
                
    def describe(self):
        
        """
        Describe all the information about the neuron
        Print out every attribute.
        """

        for k in self.__dict__.keys():
            print(k + ': {}'.format(self.__dict__[k]))

        
class Queue:
    def __init__(self, q_size):
        self.q_size = q_size
        
        self.positions_dict = {'p{}'.format(i):0 for i in range(self.q_size)}

    def rotate_positions(self):
        for i in range(len(self.positions_dict.keys()) - 1):
            self.temp = self.positions_dict['p{}'.format(i+1)]
            self.positions_dict['p{}'.format(i)] = self.temp
        self.positions_dict['p{}'.format(self.q_size - 1)] = 0
        del self.temp
        #Set i to 0 in Position(i) above

    def display_values(self):
        return self.__dict__

    def convert_to_list(self):
        return [self.positions_dict['p{}'.format(i)] for i in range(len(self.positions_dict.keys()))]

    def set_values(self, values):
        for i in range(len(values)):
            self.positions_dict['p{}'.format(i)] = values[i]
            
    def update_values(self, values):
        for i in range(len(values)):
            self.positions_dict['p{}'.format(i)] += values[i]
            
    def reset(self):
        for i in range(self.q_size):
            self.positions_dict['p{}'.format(i)] = 0      

###Queue tests
##q = Queue(10)
##
##qq = q.convert_to_list()
##
##q.display_values()
##q.rotate_positions()
##q.display_values()
##
##q.set_values(range(10))
##q.display_values()
##q.reset()
##q.display_values()
##        
##        
        
        
                
################################################################################
#
#                                Functions
#
################################################################################
        
def get_dict(**x):
    """
    Function that makes it easy to define a dictionary.
    """
    return x

def neuron_args_check(args_dict_list, template_args):
    """
    Check to see if all the neuron argument
    dictionaries are in the right format.
    """
    for i, dictionary in enumerate(args_dict_list):
        if dictionary.keys() != template_args.keys():
            raise Exception('\n\nDictionary {} is not in the '.format(i)+\
                    'right form.\n\nIt has these keys:\n\n{}\n\nIt should have these keys:\n\n{}'.format(dictionary.keys(), template_args.keys()))
    return 'All dictionaries are in the appropriate form.'

def make_template(template_names):
    """
    Make the neuron argument dictionary template
    in order to check to see if the created neuron
    argument dictionaries have the same keys as the template.]
    """
    template = {}
    for name in template_names[:-1]:
        template[name] = None
    template[template_names[-1]] = {}
    return template

def make_pre_post_connections(connection_list):
    """

    Connect a presynaptic neuron (pre_n) to a postsynaptic neuron (post_n).

    Takes a list of length 2 lists.
    In length 2 list, the first element is the presynaptic neuron,
    and the second element is the postsynaptic neuron.
    
    """
    for i in range(len(connection_list)):

        if (type(connection_list[i][0]) != list) and (type(connection_list[i][1]) != list):
                pre_n = connection_list[i][0]
                post_n = connection_list[i][1]
                pre_n.add_post(post_n)
                post_n.add_pre(pre_n)
                    
        if (type(connection_list[i][0]) == list) and (type(connection_list[i][1]) == list):
            for j in range(len(connection_list[i][0])):
                for k in range(len(connection_list[i][1])):
                    pre_n = connection_list[i][0][j]
                    post_n = connection_list[i][1][k]
                    pre_n.add_post(post_n)
                    post_n.add_pre(pre_n)
                    
        if (type(connection_list[i][0]) == list) and (type(connection_list[i][1]) != list):
            post_n = connection_list[i][1]
            for j in range(len(connection_list[i][0])):
                pre_n = connection_list[i][0][j]
                pre_n.add_post(post_n)
                post_n.add_pre(pre_n)
                
        if (type(connection_list[i][0]) != list) and (type(connection_list[i][1]) == list):
            
            pre_n = connection_list[i][0]
            for j in range(len(connection_list[i][1])):
                post_n = connection_list[i][1][j]
                pre_n.add_post(post_n)
                post_n.add_pre(pre_n)
            

def generate_AP_times(p_array, n_tests):
    """

    Function that generates the arrival
    of action potentials in a particular instant.

    Arguments
    ---------
    
    p-array : (array_like) 
               Each entry is a probability  of occurance for
               the neuron action potential firing
    n_tests : (int)
              The number of total tests to run.
    

    Returns
    -------

    reactions_array : (array-like)
                        A numpy array of the shape (n_tests,len(p_array))
                        reactions_array[i] is the ith set of firing preneurons.
                        
    """
    reactions_array = np.zeros((len(p_array), n_tests))
    for j in range(n_tests):
        x = np.random.uniform(0,1)
        for i in range(len(p_array)):
            if x <= p_array[i]:
                reactions_array[i][j] = 1
            else:
                reactions_array[i][j] = 0
                
    return reactions_array.astype(int).T

def generate_test_neurons(n, n_args_ex):
    test_args = n_args_ex.copy()
    neuron_dict = {}
    for i in range(1, n+1):
        test_args['name'] = 'n{}'.format(i)
        neuron_dict[i] = Neuron(test_args, n_tests)
        
    return neuron_dict

def update_network(firing_neurons, events):
    """
    Firing_neurons is a list of neurons, events is a list of 0's and 1's.
    If the i-th event is a 1, fire firing_neurons[i], otherwise do nothing.
    
    It updates all the post neurons of the firing neurons.

    Arguments
    ---------

    firing_neurons : (list)
                     List of neurons
    events : (list)
            List of 0's and 1's that indicate whether or not firing_neurons[i]
            will fire an action potential or not.
    
    """
    
    #MAY HAVE ISSUES IF NETWORK HAS FEEDBACK LOOPS
    #BECOMES TOO COMPLEX - INFINITE RECURSION

    if len(firing_neurons) != len(events):
        raise Exception('Firing neurons and events are not the same length.')

    #Get all the active firing neurons for this instance.
    active_firing_neurons = []
    for i in range(len(events)):
        if events[i] == 1:
            active_firing_neurons.append(firing_neurons[i])

    #Initiate action potentials from the active firing neurons.
    #If post neurons after the pre neuron AP's reach a voltage over the threshold
    #then initiate action potentials in those neurons and set their voltages to 0.
    new_firing_neurons = []
    for FN in active_firing_neurons:
        FN.AP()
        for FN_2_key in FN.post().keys():
            if FN.post()[FN_2_key].v >= \
               FN.post()[FN_2_key].vth:
                new_firing_neurons.append(FN.post()[FN_2_key])
    if new_firing_neurons != []:
        new_events = np.ones(len(new_firing_neurons))
        for k in new_firing_neurons:
            k.v = 0
        update_network(new_firing_neurons, new_events) #Recursive step.


##p_array = [0.2, 0.5, 0.8] 
##n_tests = 1000
##a = generate_AP_times(p_array, n_tests) #a[i] is the i-th instance of time


################################################################################
#
#                                Code
#
################################################################################

n_tests = 100

timer = 0


#Create neuron argument template for checking to see if arguments are correct
template_names = ['name', 'n_type', 'M', 'E', 'k',
                  'pr', 'f', 'v0', 'vth', 'tv', 'kv', 'v', 'AP_length','A','tau', 'other']
template_args = make_template(template_names)

#Create 4 neurons: An excitatory neuron (ex), and inhibitory neuron 
#effecting the probability of release of (ex), an inhibitory neuron (inh_v)
#to effect a postsynaptic neuron (post)

#Excitatory neuron dictionary
n_args_ex = get_dict(name = 'ex_1', n_type = 'ex', M = 10, E = 5, k = 1,
                       pr = 0.5, f = 1, v0 = 0,
                       vth = 3, tv = 10, kv = 0.01, v = 0, AP_length = 10,
                     A= 1, tau = 10, other = None)

#other dictionary for the inhibitory neuron that causes a 20% release
#in the pr variable of the postsynaptic neurons it innervates.
inh_dict = {'pr': 0.8} 
n_args_inh_v = get_dict(name = 'inh_1', n_type = 'inh_v', M = 10, E = 5,
                        k = 1, pr = 0.5, f = 1, v0 = 0, vth = 3, tv = 10,
                        kv = 0.01, v = 0,AP_length = 10, A = 1, tau = 10,
                        other = inh_dict)

n_args_post_inh_pr = get_dict(name = 'inh_1', n_type = 'inh_pr', M = 10, E = 5,
                        k = 1, pr = 0.5, f = 1, v0 = 0, vth = 3, tv = 10,
                        kv = 0.01, v = 0, AP_length = 10, A = 1, tau = 10,
                              other = inh_dict)
n_args_post_inh_pr_2 = get_dict(name = 'inh_2', n_type = 'inh_pr', M = 10, E = 5,
                        k = 1, pr = 0.5, f = 1, v0 = 0, vth = 3, tv = 10,
                        kv = 0.01, v = 0, AP_length = 10, A = 1, tau = 10,
                              other = inh_dict)
n_args_post_inh_pr_3 = get_dict(name = 'inh_3', n_type = 'inh_pr', M = 10, E = 5,
                        k = 1, pr = 0.5, f = 1, v0 = 0, vth = 3, tv = 10,
                        kv = 0.01, v = 0, AP_length = 10, A = 1, tau = 10,
                              other = inh_dict)


n_args_post_inh_pr_4 = get_dict(name = 'inh_4', n_type = 'inh_pr', M = 10, E = 5,
                        k = 1, pr = 0.5, f = 1, v0 = 0, vth = 3, tv = 10,
                        kv = 0.01, v = 0, AP_length = 10, A = 1, tau = 10,
                              other = inh_dict)



##bad_dict = get_dict(bad1 = None, bad2 = None)
##bad_args_dict_list = [neuron_args1, neuron_args2, bad_dict]
##
###Check to make sure all neuron parameters are in the correct form.
###CODE WILL RAISE AN ERROR HERE
##neuron_args_check(bad_args_dict_list, template_args)

#Code works here
args_dict_list = [n_args_ex, n_args_inh_v, n_args_post_inh_pr]
neuron_args_check(args_dict_list, template_args)


#Create the two neurons
N_ex = Neuron(n_args_ex, n_tests)
N_inh_v = Neuron(n_args_inh_v, n_tests)
N_post_inh_pr = Neuron(n_args_post_inh_pr, n_tests)

#Make N2 a presynaptic neuron to postsynaptic neuron N1.
connection_list = [[N_ex, N_post_inh_pr], [N_inh_v, N_post_inh_pr],
                   [N_post_inh_pr, N_ex]]
make_pre_post_connections(connection_list)

###Test for connecting N2 and N3 to N1, GOOD TEST
##N1 = Neuron(n_args_ex, n_tests)
##N2 = Neuron(n_args_post_inh_pr, n_tests)
##N3 = Neuron(n_args_post_inh_pr_2, n_tests)
##make_pre_post_connections([[N2, N1], [N3, N1]])
##N2.AP()
##N3.AP()
##N1.preneuron_voltage_contributions



###Test for connecting N2 to N1 and N3
##N1 = Neuron(n_args_ex, n_tests)
##N2 = Neuron(n_args_post_inh_pr, n_tests)
##N3 = Neuron(n_args_post_inh_pr_2, n_tests)
##N4 = Neuron(n_args_post_inh_pr_3, n_tests)
##N5 = Neuron(n_args_post_inh_pr_4, n_tests)
##make_pre_post_connections([[N2, N1], [N2, N3]])
##N2.AP()
##N1.describe()
##N3.describe()
##
##




#Test to update voltages sequentially

args_dict_list = [n_args_ex, n_args_post_inh_pr,
                  n_args_post_inh_pr_2, n_args_post_inh_pr_3,
                  n_args_post_inh_pr_4]

neuron_args_check(args_dict_list, template_args)

p_array = [0.7, 0.7] 
n_tests = 1000
reaction_times = generate_AP_times(p_array, n_tests) #a[i] is the i-th instance of time

N1 = Neuron(n_args_ex, n_tests)
N2 = Neuron(n_args_post_inh_pr, n_tests)
N3 = Neuron(n_args_post_inh_pr_2, n_tests)
N4 = Neuron(n_args_post_inh_pr_3, n_tests)
N5 = Neuron(n_args_post_inh_pr_4, n_tests)
make_pre_post_connections([[N1, N3], [N1, N4], [N2, N4], [N2, N5]])

firing_neurons = [N1, N2] #List of firing neurons
update_network(firing_neurons, reaction_times[0]) #Updates all the post neurons in the firing network.
print(N3.v, N4.v, N5.v)    

#Correctly updates N1 and N3 that are connected from N2.  





#Test 4 - Generate neurons and see how sequences work.
#Setup: 1-(3,4), 2-(4,5), 3-(6), 4-(6,7), 5-(7), 6-(8), 7-(8)

p_array = [0.7, 0.7] 
n_tests = 1000
reaction_times = generate_AP_times(p_array, n_tests) #a[i] is the i-th instance of time

tn = generate_test_neurons(8, n_args_ex) #8 test neurons, modeled after n_args_ex


c1 = [tn[1], [tn[3], tn[4]]]
c2 = [tn[2], [tn[4], tn[5]]]
c3 = [[tn[3], tn[4]], tn[6] ]
c4 = [[tn[4], tn[5]], tn[7]]
c5 = [[tn[6], tn[7]], tn[8]]

connection_list = [c1, c2, c3, c4, c5]


make_pre_post_connections(connection_list)

firing_neurons = [tn[1], tn[2]]

print(' ',tn[1].v, tn[2].v, '\n', tn[3].v, tn[4].v, tn[5].v, '\n ',
      tn[6].v, tn[7].v, '\n  ', tn[8].v)

test_reactions = [[0,0], [0,1], [1,0], [1,1]]

update_network(firing_neurons, test_reactions[np.random.randint(4)])

print(' ',tn[1].v, tn[2].v, '\n', tn[3].v, tn[4].v, tn[5].v, '\n ',
      tn[6].v, tn[7].v, '\n  ', tn[8].v)
